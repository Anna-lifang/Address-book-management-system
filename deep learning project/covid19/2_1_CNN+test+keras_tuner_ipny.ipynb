{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": " 2-1 CNN+test+keras tuner.ipny",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu-gKenzkKfG",
        "colab_type": "text"
      },
      "source": [
        "# Installing, Cloning & Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Q6ePLgmLcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorflow==2.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "enEcbOK7__2T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " !pip install keras-tuner"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdXV2NS4ETuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update dataset: !git pull\n",
        "!git clone https://github.com/casperbh96/COVID-19-Detection.git dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAdyEGF5nbf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import cv2, time\n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLMeFw5tArVx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import kerastuner\n",
        "\n",
        "kerastuner.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQPk_vZzkIr1",
        "colab_type": "text"
      },
      "source": [
        "# Loading The Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xtrZL2CO-qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_path = 'dataset/covid_dataset.csv'\n",
        "covid_image_path = 'dataset/covid_adjusted/'\n",
        "\n",
        "normal_path = 'dataset/normal_xray_dataset.csv'\n",
        "normal_image_path = 'dataset/normal_dataset/'\n",
        "\n",
        "covid_df = pd.read_csv(covid_path, usecols=['filename', 'finding'])\n",
        "normal_df = pd.read_csv(normal_path, usecols=['filename', 'finding'])\n",
        "\n",
        "normal_df = normal_df.head(99)\n",
        "\n",
        "covid_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ZJ3GaUlnLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_images = []\n",
        "covid_labels = []\n",
        "\n",
        "for index, row in covid_df.iterrows():\n",
        "    filename = row['filename']\n",
        "    label = row['finding']\n",
        "    path = covid_image_path + filename\n",
        "\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    covid_images.append(image)\n",
        "    covid_labels.append(label)\n",
        "\n",
        "normal_images = []\n",
        "normal_labels = []\n",
        "\n",
        "for index, row in normal_df.iterrows():\n",
        "    filename = row['filename']\n",
        "    label = row['finding']\n",
        "    path = normal_image_path + filename\n",
        "\n",
        "    # temporary fix while we preprocess ALL the images\n",
        "    if filename == '4c268764-b5e5-4417-85a3-da52916984d8.jpg':\n",
        "        break\n",
        "\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    normal_images.append(image)\n",
        "    normal_labels.append(label)\n",
        "\n",
        "# normalize to interval of [0,1]\n",
        "covid_images = np.array(covid_images) / 255\n",
        "\n",
        "# normalize to interval of [0,1]\n",
        "normal_images = np.array(normal_images) / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4pCGvdKZXe0",
        "colab_type": "text"
      },
      "source": [
        "# Splitting Datasets Into Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncFamjBeZXCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "# split into training(0.7) and testing(0.15) and validation(0.15)\n",
        "covid_x_train, covid_x_val, covid_y_train, covid_y_val= train_test_split(\n",
        "    covid_images, covid_labels, test_size=0.3)\n",
        "covid_x_test, covid_x_val, covid_y_test, covid_y_val= train_test_split(\n",
        "    covid_x_val, covid_y_val, test_size=0.5)\n",
        "\n",
        "normal_x_train, normal_x_val, normal_y_train, normal_y_val = train_test_split(\n",
        "    normal_images, normal_labels, test_size=0.3)\n",
        "normal_x_test, normal_x_val, normal_y_test, normal_y_val = train_test_split(\n",
        "    normal_x_val, normal_y_val, test_size=0.5)\n",
        "\n",
        "\n",
        "\n",
        "X_train = np.concatenate((normal_x_train, covid_x_train), axis=0)\n",
        "X_val = np.concatenate((normal_x_val, covid_x_val), axis=0)\n",
        "X_test = np.concatenate((normal_x_test, covid_x_test), axis=0)\n",
        "y_train = np.concatenate((normal_y_train, covid_y_train), axis=0)\n",
        "y_val = np.concatenate((normal_y_val, covid_y_val), axis=0)\n",
        "y_test = np.concatenate((normal_y_test, covid_y_test), axis=0)\n",
        "\n",
        "# make labels into categories - either 0 or 1\n",
        "y_train = LabelBinarizer().fit_transform(y_train)\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "y_val = LabelBinarizer().fit_transform(y_val)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "y_test = LabelBinarizer().fit_transform(y_test)\n",
        "y_test = to_categorical(y_test)# split into training(0.7) and testing(0.15) and validation(0.15)\n",
        "covid_x_train, covid_x_val, covid_y_train, covid_y_val= train_test_split(\n",
        "    covid_images, covid_labels, test_size=0.3)\n",
        "covid_x_test, covid_x_val, covid_y_test, covid_y_val= train_test_split(\n",
        "    covid_x_val, covid_y_val, test_size=0.5)\n",
        "\n",
        "normal_x_train, normal_x_val, normal_y_train, normal_y_val = train_test_split(\n",
        "    normal_images, normal_labels, test_size=0.3)\n",
        "normal_x_test, normal_x_val, normal_y_test, normal_y_val = train_test_split(\n",
        "    normal_x_val, normal_y_val, test_size=0.5)\n",
        "\n",
        "\n",
        "\n",
        "X_train = np.concatenate((normal_x_train, covid_x_train), axis=0)\n",
        "X_val = np.concatenate((normal_x_val, covid_x_val), axis=0)\n",
        "X_test = np.concatenate((normal_x_test, covid_x_test), axis=0)\n",
        "y_train = np.concatenate((normal_y_train, covid_y_train), axis=0)\n",
        "y_val = np.concatenate((normal_y_val, covid_y_val), axis=0)\n",
        "y_test = np.concatenate((normal_y_test, covid_y_test), axis=0)\n",
        "\n",
        "# make labels into categories - either 0 or 1\n",
        "y_train = LabelBinarizer().fit_transform(y_train)\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "y_val = LabelBinarizer().fit_transform(y_val)\n",
        "y_val = to_categorical(y_val)\n",
        "\n",
        "y_test = LabelBinarizer().fit_transform(y_test)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKJMqf0kA51l",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "train_aug = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKqp9ZPDkFXP",
        "colab_type": "text"
      },
      "source": [
        "# Modeling With Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6amZPlFJJpRN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten, Activation\n",
        "from tensorflow.keras.layers import BatchNormalization,Dropout\n",
        "from kerastuner.tuners import RandomSearch\n",
        "from kerastuner.engine.hyperparameters import HyperParameters\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpXIvnJIkE0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def build_model(hp):  # random search passes this hyperparameter() object \n",
        "    vggModel = VGG19(weights=\"imagenet\", include_top=False,\n",
        "    input_tensor=Input(shape=X_train.shape[1:]))\n",
        "\n",
        "    outputs = vggModel.output\n",
        "    outputs = Flatten(name=\"flatten\")(outputs)\n",
        "    outputs = Dropout(0.5)(outputs)\n",
        "    outputs = Dense(2, activation=\"softmax\")(outputs)\n",
        "\n",
        "    model = Model(inputs=vggModel.input, outputs=outputs)\n",
        "    model.summary()\n",
        "    for layer in vggModel.layers:\n",
        "       layer.trainable = False\n",
        "\n",
        "\n",
        "    model.compile(optimizer=keras.optimizers.Adam(\n",
        "                hp.Float(\n",
        "                    'learning_rate',\n",
        "                    min_value=1e-4,\n",
        "                    max_value=1e-2,\n",
        "                    sampling='LOG',\n",
        "                    default=1e-3\n",
        "                )\n",
        "            ),\n",
        "                  loss=\"categorical_crossentropy\",\n",
        "                  metrics=[\"accuracy\"])\n",
        "    return model\n",
        "   \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t92S9v3vOgzm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "LOG_DIR = f\"{int(time.time())}\"\n",
        "\n",
        "tuner = RandomSearch(\n",
        "    build_model,\n",
        "    objective='val_accuracy',\n",
        "    max_trials=2,  # how many model variations to test?\n",
        "    executions_per_trial=20,  # how many trials per variation? (same model could perform differently)\n",
        "    directory=LOG_DIR)\n",
        "# earlystop = EarlyStopping(monitor = 'loss',patience = 5, baseline = None)\n",
        "tuner.search(train_aug.flow(X_train, y_train, batch_size=32),\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    validation_steps=len(X_val) / 32,\n",
        "                    steps_per_epoch=len(X_train) / 32,\n",
        "                    epochs=100)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gtMbDEgCbcqA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tuner.get_best_hyperparameters()[0].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HYeNwjJjbik2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tuner.get_best_models()[0].summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I7Eevr38iBW7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "modelBest = tuner.get_best_models()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eLsoUBQ6iNK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "history = modelBest.fit(train_aug.flow(X_train, y_train, batch_size=32),\n",
        "                    validation_data=(X_val, y_val),\n",
        "                    validation_steps=len(X_val) / 32,\n",
        "                    steps_per_epoch=len(X_train) / 32,\n",
        "                    epochs=200)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RRiBHkAR81bV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc_scores = list()\n",
        "acc = modelBest.evaluate(X_test, y_test, verbose=0)\n",
        "acc_scores.append(acc[1])\n",
        "print('Accuracy scores: ', acc_scores)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX5Cbm4U3kmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = modelBest.predict(X_test, batch_size=32)\n",
        "y_pred_covid = modelBest.predict(covid_x_test, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFpJ4lSs3sig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_covid = LabelBinarizer().fit_transform(covid_y_test)\n",
        "y_test_covid = to_categorical(y_test_covid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KNnNLSnr7vdm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkT6IZDt34ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Training', 'Validation'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1pDXJ9h3-Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Training', 'Validation'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxjfXNKUFOwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('dataset/normal_dataset/0b421aea-6e0f-4faf-a4bf-4a82445d0e35.jpg', target_size = (224,224))\n",
        "#test_image = image.load_img('dataset/covid_adjusted/covid-19-pneumonia-rapidly-progressive-12-hours.jpg.jpg', target_size = (224,224))\n",
        "\n",
        "\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = test_image *1./255\n",
        "\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "test_image = np.vstack([test_image ])\n",
        "result = modelBest.predict(test_image,batch_size=32)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzrC7q7hD3Mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "img=mpimg.imread('dataset/normal_dataset/0b421aea-6e0f-4faf-a4bf-4a82445d0e35.jpg')\n",
        "#img=mpimg.imread('dataset/covid_adjusted/covid-19-pneumonia-rapidly-progressive-12-hours.jpg.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt=plt.title('Chest X-ray ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlQFbn_6GTAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if result[0][0]<result[0][1]:\n",
        "\n",
        "    prediction = 'normal'\n",
        "else:\n",
        "    prediction = 'covid'\n",
        "    \n",
        "print(\"AI's prediction is: \"+ prediction)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}