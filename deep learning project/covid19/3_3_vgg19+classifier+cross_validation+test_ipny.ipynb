{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_3 vgg19+classifier+cross validation+test.ipny",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu-gKenzkKfG",
        "colab_type": "text"
      },
      "source": [
        "# Installing, Cloning & Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Q6ePLgmLcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow-gpu"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UdXV2NS4ETuT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Update dataset: !git pull\n",
        "!git clone https://github.com/casperbh96/COVID-19-Detection.git dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAdyEGF5nbf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import cv2, time\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQPk_vZzkIr1",
        "colab_type": "text"
      },
      "source": [
        "# Loading The Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xtrZL2CO-qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_path = 'dataset/covid_dataset.csv'\n",
        "covid_image_path = 'dataset/covid_adjusted/'\n",
        "\n",
        "normal_path = 'dataset/normal_xray_dataset.csv'\n",
        "normal_image_path = 'dataset/normal_dataset/'\n",
        "\n",
        "covid_df = pd.read_csv(covid_path, usecols=['filename', 'finding'])\n",
        "normal_df = pd.read_csv(normal_path, usecols=['filename', 'finding'])\n",
        "\n",
        "normal_df = normal_df.head(99)\n",
        "\n",
        "covid_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ZJ3GaUlnLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_images = []\n",
        "covid_labels = []\n",
        "\n",
        "for index, row in covid_df.iterrows():\n",
        "    filename = row['filename']\n",
        "    label = row['finding']\n",
        "    path = covid_image_path + filename\n",
        "\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    covid_images.append(image)\n",
        "    covid_labels.append(label)\n",
        "\n",
        "normal_images = []\n",
        "normal_labels = []\n",
        "\n",
        "for index, row in normal_df.iterrows():\n",
        "    filename = row['filename']\n",
        "    label = row['finding']\n",
        "    path = normal_image_path + filename\n",
        "\n",
        "    # temporary fix while we preprocess ALL the images\n",
        "    if filename == '4c268764-b5e5-4417-85a3-da52916984d8.jpg':\n",
        "        break\n",
        "\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    normal_images.append(image)\n",
        "    normal_labels.append(label)\n",
        "\n",
        "# normalize to interval of [0,1]\n",
        "covid_images = np.array(covid_images) / 255\n",
        "\n",
        "# normalize to interval of [0,1]\n",
        "normal_images = np.array(normal_images) / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V4pCGvdKZXe0",
        "colab_type": "text"
      },
      "source": [
        "# Splitting Datasets Into Training and Testing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncFamjBeZXCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# split into training and testing\n",
        "covid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(\n",
        "    covid_images, covid_labels, test_size=0.2)\n",
        "\n",
        "normal_x_train, normal_x_test, normal_y_train, normal_y_test = train_test_split(\n",
        "    normal_images, normal_labels, test_size=0.2)\n",
        "\n",
        "X_train = np.concatenate((normal_x_train, covid_x_train), axis=0)\n",
        "X_test = np.concatenate((normal_x_test, covid_x_test), axis=0)\n",
        "y_train = np.concatenate((normal_y_train, covid_y_train), axis=0)\n",
        "y_test = np.concatenate((normal_y_test, covid_y_test), axis=0)\n",
        "\n",
        "# make labels into categories - either 0 or 1\n",
        "y_train = LabelBinarizer().fit_transform(y_train)\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "y_test = LabelBinarizer().fit_transform(y_test)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKqp9ZPDkFXP",
        "colab_type": "text"
      },
      "source": [
        "# Modeling With Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpXIvnJIkE0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Flatten # Convert pools feature map into this large feature vector\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D\n",
        "\n",
        "vggModel = VGG19(weights=\"imagenet\", include_top=False,\n",
        "    input_tensor=Input(shape=(224, 224, 3)))\n",
        "outputs = vggModel.output\n",
        "\n",
        "outputs = Conv2D(512,(1, 1), strides = (1, 1), name = 'conv0')(outputs)\n",
        "outputs = BatchNormalization(axis = 3, name = 'bn0')(outputs)\n",
        "outputs = Activation('relu')(outputs)\n",
        "outputs = MaxPooling2D((2, 2), name='max_pool0')(outputs) \n",
        "outputs = Conv2D(512,(2, 2), strides = (1, 1), name = 'conv1')(outputs)\n",
        "outputs = BatchNormalization(axis = 3, name = 'bn1')(outputs)\n",
        "outputs = Activation('relu')(outputs) \n",
        "\n",
        "outputs = Dropout(0.5)(outputs)\n",
        "\n",
        "outputs = Conv2D(512,(2, 2), strides = (1, 1), name = 'conv2')(outputs)\n",
        "outputs = BatchNormalization(axis = 3, name = 'bn2')(outputs)\n",
        "outputs = Activation('relu')(outputs) \n",
        "outputs = MaxPooling2D((2, 2), name='max_pool1')(outputs)\n",
        "\n",
        "outputs = Flatten(name=\"flatten\")(outputs)\n",
        "outputs = Dropout(0.5)(outputs)\n",
        "outputs = Dense(2, activation=\"softmax\")(outputs)\n",
        "\n",
        "model = Model(inputs=vggModel.input, outputs=outputs)\n",
        "\n",
        "for layer in vggModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer='adam', \n",
        "        metrics=['accuracy']\n",
        ")\n",
        "\n",
        "train_aug = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CccBEhF9Oadd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3IWX_d0F_6_p",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import KFold\n",
        "# cross validation\n",
        "# split into training and testing\n",
        "n_splits=5\n",
        "acc_scores = list()\n",
        "\n",
        "\n",
        "kf = KFold(n_splits=n_splits, random_state=1, shuffle=True)\n",
        "kf.get_n_splits(X_train)\n",
        "\n",
        "for fold, (train_index, test_index) in enumerate(kf.split(X_train)):\n",
        "  print('\\n Fold %d' % (fold))\n",
        "  X_trainf,X_valf=X_train[train_index],X_train[test_index]\n",
        "  y_trainf,y_valf=y_train[train_index],y_train[test_index]\n",
        "\n",
        " # make labels into categories - either 0 or 1\n",
        "  #y_trainf = LabelBinarizer().fit_transform(y_trainf)\n",
        " # y_trainf = to_categorical(y_trainf)\n",
        "\n",
        "  #y_valf = LabelBinarizer().fit_transform(y_valf)\n",
        "  #y_valf= to_categorical(y_valf)\n",
        "\n",
        "  history = model.fit(train_aug.flow(X_trainf, y_trainf, batch_size=32),\n",
        "                    validation_data=(X_valf, y_valf),\n",
        "                    validation_steps=len(X_valf) / 32,\n",
        "                    steps_per_epoch=len(X_trainf) / 32,\n",
        "                    epochs=96)\n",
        "  acc = model.evaluate(X_test, y_test, verbose=0)\n",
        "  acc_scores.append(acc[1])\n",
        "  print('Fold %d: Accuracy %.2f%%' % (fold, acc[1] * 100))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmhjUW3wABb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def average(numbers):\n",
        "    \"\"\"\n",
        "    Return the sample arithmetic mean of data.\n",
        "    :param numbers: a list of float\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    try:\n",
        "        return float(sum(numbers)) / max(len(numbers), 1)\n",
        "    except ZeroDivisionError:\n",
        "        return 0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DC5Dy4jyAHBg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('Accuracy scores: ', acc_scores)\n",
        "mean_acc = average(acc_scores)\n",
        "print('=====================')\n",
        "print('Mean Accuracy %f' % mean_acc)\n",
        "print('=====================')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX5Cbm4U3kmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test, batch_size=32)\n",
        "y_pred_covid = model.predict(covid_x_test, batch_size=32)\n",
        "print(y_pred,y_pred_covid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFpJ4lSs3sig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_covid = LabelBinarizer().fit_transform(covid_y_test)\n",
        "y_test_covid = to_categorical(y_test_covid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG7MABfK3zGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkT6IZDt34ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Training', 'Testing'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1pDXJ9h3-Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.style.use('dark_background')\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Training', 'Testing'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxjfXNKUFOwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('dataset/normal_dataset/0b421aea-6e0f-4faf-a4bf-4a82445d0e35.jpg', target_size = (224,224))\n",
        "#test_image = image.load_img('dataset/covid_adjusted/covid-19-pneumonia-rapidly-progressive-12-hours.jpg.jpg', target_size = (224,224))\n",
        "\n",
        "\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = test_image *1./255\n",
        "\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "test_image = np.vstack([test_image ])\n",
        "result = model.predict(test_image,batch_size=32)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzrC7q7hD3Mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "img=mpimg.imread('dataset/normal_dataset/0b421aea-6e0f-4faf-a4bf-4a82445d0e35.jpg')\n",
        "#img=mpimg.imread('dataset/covid_adjusted/covid-19-pneumonia-rapidly-progressive-12-hours.jpg.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt=plt.title('Chest X-ray ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlQFbn_6GTAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if result[0][0]<result[0][1]:\n",
        "\n",
        "    prediction = 'normal'\n",
        "else:\n",
        "    prediction = 'covid'\n",
        "    \n",
        "print(\"AI's prediction is: \"+ prediction)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}