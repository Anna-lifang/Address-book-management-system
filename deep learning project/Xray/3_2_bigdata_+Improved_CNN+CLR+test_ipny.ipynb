{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "3_2 bigdata +Improved CNN+CLR+test.ipny",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xu-gKenzkKfG",
        "colab_type": "text"
      },
      "source": [
        "# Installing, Cloning & Importing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q8Q6ePLgmLcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install --upgrade tensorflow==2.1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l32GuHYNAmfs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "467FIGXVA6Xs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = \"/content/gdrive/My Drive/Kaggle\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nSsFELMrA-GJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!kaggle datasets download -d paultimothymooney/chest-xray-pneumonia"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eSgmgfw-BFl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!unzip /content/chest-xray-pneumonia.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hAdyEGF5nbf-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import numpy as np\n",
        "import cv2, time\n",
        "import tensorflow as tf\n",
        "\n",
        "tf.__version__"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wQPk_vZzkIr1",
        "colab_type": "text"
      },
      "source": [
        "# Loading The Datasets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2xtrZL2CO-qN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_path = '/content/gdrive/My Drive/Kaggle/pneumonia.csv'\n",
        "covid_image_path = '/content/chest_xray/train/PNEUMONIA/'\n",
        "\n",
        "normal_path = '/content/gdrive/My Drive/Kaggle/normal.csv'\n",
        "normal_image_path = '/content/chest_xray/train/NORMAL/'\n",
        "\n",
        "covid_df = pd.read_csv(covid_path, usecols=['filename', 'finding'])\n",
        "normal_df = pd.read_csv(normal_path, usecols=['filename', 'finding'])\n",
        "\n",
        "normal_df = normal_df.head(99)\n",
        "\n",
        "covid_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r0ZJ3GaUlnLN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "covid_images = []\n",
        "covid_labels = []\n",
        "\n",
        "for index, row in covid_df.iterrows():\n",
        "    filename = row['filename']\n",
        "    label = row['finding']\n",
        "    path = covid_image_path + filename\n",
        "\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.resize(image,(224,224))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    covid_images.append(image)\n",
        "    covid_labels.append(label)\n",
        "\n",
        "normal_images = []\n",
        "normal_labels = []\n",
        "\n",
        "for index, row in normal_df.iterrows():\n",
        "    filename = row['filename']\n",
        "    label = row['finding']\n",
        "    path = normal_image_path + filename\n",
        "\n",
        "    # temporary fix while we preprocess ALL the images\n",
        "    if filename == 'NORMAL2-IM-0381-0001.jpeg':\n",
        "        break\n",
        "\n",
        "    image = cv2.imread(path)\n",
        "    image = cv2.resize(image,(224,224))\n",
        "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "    \n",
        "    normal_images.append(image)\n",
        "    normal_labels.append(label)\n",
        "\n",
        "# normalize to interval of [0,1]\n",
        "covid_images = np.array(covid_images) / 255\n",
        "\n",
        "# normalize to interval of [0,1]\n",
        "normal_images = np.array(normal_images) / 255"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncFamjBeZXCb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "# split into training and testing\n",
        "covid_x_train, covid_x_test, covid_y_train, covid_y_test = train_test_split(\n",
        "    covid_images, covid_labels, test_size=0.2)\n",
        "\n",
        "normal_x_train, normal_x_test, normal_y_train, normal_y_test = train_test_split(\n",
        "    normal_images, normal_labels, test_size=0.2)\n",
        "\n",
        "X_train = np.concatenate((normal_x_train, covid_x_train), axis=0)\n",
        "X_test = np.concatenate((normal_x_test, covid_x_test), axis=0)\n",
        "y_train = np.concatenate((normal_y_train, covid_y_train), axis=0)\n",
        "y_test = np.concatenate((normal_y_test, covid_y_test), axis=0)\n",
        "\n",
        "# make labels into categories - either 0 or 1\n",
        "y_train = LabelBinarizer().fit_transform(y_train)\n",
        "y_train = to_categorical(y_train)\n",
        "\n",
        "y_test = LabelBinarizer().fit_transform(y_test)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WKqp9ZPDkFXP",
        "colab_type": "text"
      },
      "source": [
        "# Modeling With Keras"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpXIvnJIkE0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "from keras.callbacks import *\n",
        "from clr_callback import *\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications import VGG19\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input\n",
        "from tensorflow.keras.layers import Flatten # Convert pools feature map into this large feature vector\n",
        "from tensorflow.keras.layers import Dropout\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Conv2D, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D\n",
        "from keras import optimizers\n",
        "\n",
        "#cycle learning rate\n",
        "\n",
        "# define the minimum learning rate, maximum learning rate, batch size,\n",
        "# step size, CLR method, and number of epochs\n",
        "MIN_LR = 1e-4\n",
        "MAX_LR = 1e-2\n",
        "BATCH_SIZE = 32\n",
        "STEP_SIZE = 12\n",
        "#CLR_METHOD = \"triangular\"\n",
        "CLR_METHOD = \"triangular2\"\n",
        "\n",
        "clr = CyclicLR(base_lr=MIN_LR, max_lr=MAX_LR,\n",
        "              step_size=STEP_SIZE,mode=CLR_METHOD)\n",
        "\n",
        "\n",
        "vggModel = VGG19(weights=\"imagenet\", include_top=False,\n",
        "    input_tensor=Input(shape=(224, 224, 3)))\n",
        "outputs = vggModel.output\n",
        "\n",
        "outputs = Conv2D(512,(1, 1), strides = (1, 1), name = 'conv0')(outputs)\n",
        "outputs = BatchNormalization(axis = 3, name = 'bn0')(outputs)\n",
        "outputs = Activation('relu')(outputs) \n",
        "outputs = MaxPooling2D((2, 2), name='max_pool0')(outputs) \n",
        "\n",
        "outputs = Conv2D(512,(1, 1), strides = (1, 1), name = 'conv1')(outputs)\n",
        "outputs = BatchNormalization(axis = 3, name = 'bn1')(outputs)\n",
        "outputs = Activation('relu')(outputs)\n",
        "\n",
        "outputs = Dropout(0.5)(outputs)\n",
        "\n",
        "outputs = Conv2D(512,(1, 1), strides = (1, 1), name = 'conv2')(outputs)\n",
        "outputs = BatchNormalization(axis = 3, name = 'bn2')(outputs)\n",
        "outputs = Activation('relu')(outputs) \n",
        "outputs = MaxPooling2D((2, 2), name='max_pool1')(outputs)\n",
        "\n",
        "outputs = Flatten(name=\"flatten\")(outputs)\n",
        "outputs = Dropout(0.5)(outputs)\n",
        "outputs = Dense(2, activation=\"softmax\")(outputs)\n",
        "\n",
        "model = Model(inputs=vggModel.input, outputs=outputs)\n",
        "\n",
        "for layer in vggModel.layers:\n",
        "    layer.trainable = False\n",
        "\n",
        "model.compile(\n",
        "        loss='categorical_crossentropy', \n",
        "        optimizer='Adam', \n",
        "        metrics=['accuracy']\n",
        ")\n",
        "\n",
        "train_aug = ImageDataGenerator(\n",
        "    rotation_range=20,\n",
        "    width_shift_range=0.2,\n",
        "    height_shift_range=0.2,\n",
        "    horizontal_flip=True\n",
        ")\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8ypoe9x5MNL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "history = model.fit(train_aug.flow(X_train, y_train, batch_size=32),\n",
        "                    validation_data=(X_test, y_test),\n",
        "                    validation_steps=len(X_test) / 32,\n",
        "                    steps_per_epoch=len(X_train) / 32,\n",
        "                    epochs=100,\n",
        "                    callbacks=[clr],verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX5Cbm4U3kmB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = model.predict(X_test, batch_size=32)\n",
        "y_pred_covid = model.predict(covid_x_test, batch_size=32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFpJ4lSs3sig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_test_covid = LabelBinarizer().fit_transform(covid_y_test)\n",
        "y_test_covid = to_categorical(y_test_covid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zG7MABfK3zGc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(np.argmax(y_test, axis=1), np.argmax(y_pred, axis=1)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cfL8qFR2pUfx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# plot the learning rate history\n",
        "N = np.arange(0, len(clr.history[\"lr\"]))\n",
        "plt.figure()\n",
        "plt.plot(N, clr.history[\"lr\"])\n",
        "plt.title(\"Cyclical Learning Rate (CLR)\")\n",
        "plt.xlabel(\"Training Iterations\")\n",
        "plt.ylabel(\"Learning Rate\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkT6IZDt34ED",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.style.use('classic')\n",
        "\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Training', 'Testing'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_S6b4eM5HH3W",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "acc = model.evaluate(X_test, y_test,verbose=0)\n",
        "print(\"test acc:\"+ str(acc[1]))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1pDXJ9h3-Ia",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.figure(figsize=(10,10))\n",
        "plt.style.use('classic')\n",
        "\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "\n",
        "plt.legend(['Training', 'Testing'])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxjfXNKUFOwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = image.load_img('/content/chest_xray/test/PNEUMONIA/person1685_virus_2903.jpeg', target_size = (224,224))\n",
        "#test_image = image.load_img('dataset/covid_adjusted/covid-19-pneumonia-rapidly-progressive-12-hours.jpg.jpg', target_size = (224,224))\n",
        "\n",
        "test_image = image.img_to_array(test_image)\n",
        "test_image = test_image *1./255\n",
        "\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "test_image = np.vstack([test_image ])\n",
        "result = model.predict(test_image,batch_size=32)\n",
        "print(result)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzrC7q7hD3Mp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.image as mpimg\n",
        "\n",
        "img=mpimg.imread('/content/chest_xray/test/PNEUMONIA/person1685_virus_2903.jpeg')\n",
        "#img=mpimg.imread('dataset/covid_adjusted/covid-19-pneumonia-rapidly-progressive-12-hours.jpg.jpg')\n",
        "imgplot = plt.imshow(img)\n",
        "plt=plt.title('Chest X-ray ')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QlQFbn_6GTAd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if result[0][0]<result[0][1]:\n",
        "\n",
        "    prediction = 'normal'\n",
        "else:\n",
        "    prediction = 'covid'\n",
        "    \n",
        "print(\"AI's prediction is: \"+ prediction)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}